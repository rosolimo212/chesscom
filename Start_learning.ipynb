{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "\n",
    "# our all\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# usefull pandas settings\n",
    "pd.set_option('display.max_rows', 45000)\n",
    "pd.set_option('display.max_columns', 50000)\n",
    "pd.set_option('display.max_colwidth', 5000)\n",
    "\n",
    "# for API working and current time\n",
    "import requests\n",
    "import datetime\n",
    "\n",
    "# chess pgn-reading tool\n",
    "from pgn_parser import pgn, parser\n",
    "\n",
    "# multistreaming\n",
    "import threading\n",
    "\n",
    "# отключим предупреждения Anaconda\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "# будем отображать графики прямо в jupyter'e\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# own libs\n",
    "import sys\n",
    "sys.path.append('//home//roman_vm//my_lib//')\n",
    "\n",
    "from data_load import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_list=['date', 'time', 'color', 'score', 'rating', 'opponent_rating', 'eco']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "work_df=df[df['rated']==True]\n",
    "work_df=work_df[f_list]\n",
    "work_df['datetime']=work_df['date']+' '+work_df['time']\n",
    "\n",
    "\n",
    "\n",
    "c=pd.get_dummies(work_df['color'])\n",
    "eco=pd.get_dummies(work_df['eco'])\n",
    "work_df=pd.concat([work_df, c, eco], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "work_df=work_df.drop(columns=['time', 'datetime', 'color', 'eco'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hold=work_df[work_df['date']>='2019-08-01']\n",
    "X=work_df[work_df['date']<'2019-08-01']\n",
    "y=X['score']\n",
    "X=X.drop(columns=['score', 'date'])\n",
    "\n",
    "X=X.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     X.values, y.values, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# строит график, считает метрики\n",
    "def check(df, x, y1, y2, title):\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    print(title)\n",
    "    df[[x, y1, y2]].set_index(x).plot(title=title)\n",
    "    \n",
    "    print('correlation: ', np.corrcoef(df[y1], df[y2])[0][1])\n",
    "    \n",
    "    print('stdev: ', mean_squared_error(df[y1], df[y2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lr = LinearRegression().fit(X_train, y_train)\n",
    "lr_pred=lr.predict(X_test)\n",
    "\n",
    "print('R^2 train:', lr.score(X_train, y_train))\n",
    "print('R^2 test:', lr.score(X_test, y_test))\n",
    "print('Total: ', np.sum(y_test))\n",
    "print('Total: ', np.sum(lr.predict(X_test)))\n",
    "print('MAE train', mean_absolute_error(lr.predict(X_train), y_train))\n",
    "print('MAE test', mean_absolute_error(lr.predict(X_test), y_test))\n",
    "\n",
    "# plt.plot(range(len(y_test)), y_test, lr.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(random_state=0, solver='lbfgs', multi_class='multinomial').fit(X_train, y_train)\n",
    "\n",
    "lr_pred=lr.predict(X_test)\n",
    "\n",
    "print('R^2 train:', lr.score(X_train, y_train))\n",
    "print('R^2 test:', lr.score(X_test, y_test))\n",
    "print('Total: ', np.sum(y_test))\n",
    "print('Total: ', np.sum(lr.predict(X_test)))\n",
    "print('MAE train', mean_absolute_error(lr.predict(X_train), y_train))\n",
    "print('MAE test', mean_absolute_error(lr.predict(X_test), y_test))\n",
    "\n",
    "# plt.plot(range(len(y_test)), y_test, lr.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "xgb = xgboost.XGBRegressor()\n",
    "xgb.fit(X_train, y_train)\n",
    "print('R^2 train:', xgb.score(X_train, y_train))\n",
    "print('R^2 test:', xgb.score(X_test, y_test))\n",
    "print('Total: ', np.sum(y_test))\n",
    "print('Total: ', np.sum(xgb.predict(X_test)))\n",
    "print('MAE train', mean_absolute_error(xgb.predict(X_train), y_train))\n",
    "print('MAE test', mean_absolute_error(xgb.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model_abs_testing = list()\n",
    "xgb_model_abs_training = list()\n",
    "rng = np.arange(1,151)\n",
    "for i in rng:\n",
    "    xgb = xgboost.XGBRegressor(n_estimators=i)\n",
    "    xgb.fit(X_train, y_train)\n",
    "    xgb.score(X_test, y_test)\n",
    "    xgb_model_abs_testing.append(mean_absolute_error(xgb.predict(X_test), y_test))\n",
    "    xgb_model_abs_training.append(mean_absolute_error(xgb.predict(X_train), y_train))\n",
    "    \n",
    "find_df=pd.DataFrame(np.arange(1,151), columns=['n_estimators']).set_index('n_estimators')\n",
    "find_df['xgb_model_abs_testing_MAE']=xgb_model_abs_testing\n",
    "find_df['xgb_model_abs_training_MAE']=xgb_model_abs_training\n",
    "\n",
    "find_df.plot()\n",
    "\n",
    "stat_best_n_estimators=np.argmin(find_df['xgb_model_abs_testing_MAE'])\n",
    "ch_n_estimators=stat_best_n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model_abs_testing = list()\n",
    "xgb_model_abs_training = list()\n",
    "rng = np.arange(0.05, 0.65, 0.05)\n",
    "for i in rng:\n",
    "    xgb = xgboost.XGBRegressor(n_estimators=ch_n_estimators, random_state=17, learning_rate=i)\n",
    "    xgb.fit(X_train, y_train)\n",
    "    xgb.score(X_test, y_test)\n",
    "    xgb_model_abs_testing.append(mean_absolute_error(xgb.predict(X_test), y_test))\n",
    "    xgb_model_abs_training.append(mean_absolute_error(xgb.predict(X_train), y_train))\n",
    "    \n",
    "find_df=pd.DataFrame(rng, columns=['learning_rate']).set_index('learning_rate')\n",
    "find_df['xgb_model_abs_testing_MAE']=xgb_model_abs_testing\n",
    "find_df['xgb_model_abs_training_MAE']=xgb_model_abs_training\n",
    "\n",
    "find_df.plot()\n",
    "\n",
    "stat_best_learning_rate=np.argmin(find_df['xgb_model_abs_testing_MAE'])\n",
    "ch_learning_rate=0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model_abs_testing = list()\n",
    "xgb_model_abs_training = list()\n",
    "rng = np.arange(1, 11)\n",
    "for i in rng:\n",
    "    xgb = xgboost.XGBRegressor(n_estimators=ch_n_estimators, random_state=17, learning_rate=ch_learning_rate, max_depth=i)\n",
    "    xgb.fit(X_train, y_train)\n",
    "    xgb.score(X_test, y_test)\n",
    "    xgb_model_abs_testing.append(mean_absolute_error(xgb.predict(X_test), y_test))\n",
    "    xgb_model_abs_training.append(mean_absolute_error(xgb.predict(X_train), y_train))\n",
    "    \n",
    "find_df=pd.DataFrame(rng, columns=['max_depth']).set_index('max_depth')\n",
    "find_df['xgb_model_abs_testing_MAE']=xgb_model_abs_testing\n",
    "find_df['xgb_model_abs_training_MAE']=xgb_model_abs_training\n",
    "\n",
    "find_df.plot()\n",
    "\n",
    "stat_best_max_depth=np.argmin(find_df['xgb_model_abs_testing_MAE'])\n",
    "ch_max_depth=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch_max_depth=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "xgb = xgboost.XGBRegressor(n_estimators=ch_n_estimators, random_state=17, learning_rate=ch_learning_rate, max_depth=ch_max_depth)\n",
    "xgb.fit(X_train, y_train)\n",
    "print('R^2 train:', xgb.score(X_train, y_train))\n",
    "print('R^2 test:', xgb.score(X_test, y_test))\n",
    "print('Total: ', np.sum(y_test))\n",
    "print('Total: ', np.sum(xgb.predict(X_test)))\n",
    "print('MAE train', mean_absolute_error(xgb.predict(X_train), y_train))\n",
    "print('MAE test', mean_absolute_error(xgb.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_test=pd.DataFrame(X_test, columns=X.columns)\n",
    "res_test['fact']=y_test\n",
    "res_test['predict']=xgb.predict(X_test)\n",
    "\n",
    "\n",
    "sh=res_test.sample(150).reset_index()\n",
    "sh['ind']=sh.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check(sh, 'ind', 'fact', 'predict', 'gg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df = pd.DataFrame(data=xgb.feature_importances_.reshape(1, -1), columns=X.columns).sort_values(axis=1, by=[0], ascending=False).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_test.groupby('month').mean()[['fact']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_test.groupby('hour').mean()[['fact']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
